{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "efa9783b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Supress pytorch pickle load warnings\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "# Torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Normal\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# Logging\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "# Library imports\n",
    "import gdiffusion as gd\n",
    "import util\n",
    "import util.chem as chem\n",
    "import util.visualization as vis\n",
    "import util.stats as gdstats\n",
    "\n",
    "\n",
    "import gdiffusion.bayesopt as bayesopt\n",
    "from gdiffusion.classifier.extinct_predictor import EsmClassificationHead\n",
    "\n",
    "device = util.util.get_device()\n",
    "print(f\"device: {device}\")\n",
    "\n",
    "# peptide diffusion\n",
    "DIFFUSION_PATH = \"saved_models/peptide_model_v1-20.pt\"\n",
    "PEPTIDE_VAE_PATH = \"saved_models/peptide_vae/peptide-vae.ckpt\"\n",
    "PEPTIDE_VAE_VOCAB_PATH = \"saved_models/peptide_vae/vocab.json\"\n",
    "EXTINCT_PREDICTOR_PATH = \"saved_models/extinct_model8417\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3de0ae86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model created successfully\n",
      "- Total parameters: 225,056,257\n",
      "- Trainable parameters: 225,056,257\n",
      "- Model size: 858.5 MB\n",
      "- Device: cuda:0\n",
      "- Model Name: LatentDiffusionModel\n",
      "- Device: cuda:0\n",
      "- Model Name: LatentDiffusionModel\n",
      "loading model from saved_models/peptide_vae/peptide-vae.ckpt\n",
      "Enc params: 2,675,904\n",
      "Dec params: 360,349\n"
     ]
    }
   ],
   "source": [
    "classifier = torch.load(EXTINCT_PREDICTOR_PATH)\n",
    "classifier.eval().to(device)\n",
    "\n",
    "diffusion = gd.create_peptide_diffusion_model(DIFFUSION_PATH, device=device)\n",
    "peptide_vae = gd.load_vae_peptides(path_to_vae_statedict=PEPTIDE_VAE_PATH, vocab_path=PEPTIDE_VAE_VOCAB_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6c65c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "decode = lambda z: gd.latent_to_peptides(z, vae=peptide_vae)\n",
    "encode = lambda peptide_str: gd.peptides_to_latent(peptide_str, vae=peptide_vae)\n",
    "\n",
    "def sample_random(batch_size):\n",
    "    return torch.randn(size=(batch_size, 256), device=device)\n",
    "\n",
    "def classify(z):\n",
    "    return torch.softmax(classifier(z), dim=1)\n",
    "\n",
    "def sample(batch_size, cond_fn=None):\n",
    "    return diffusion.sample(batch_size=batch_size, cond_fn=cond_fn).reshape(batch_size, 256)\n",
    "\n",
    "def eval_probs(z):\n",
    "    probs = classify(z)\n",
    "    print(f\"Diffusion Probs: {probs}\")\n",
    "    argmax = torch.argmax(probs, dim=1)\n",
    "    print(f\"Percent Extinct: {argmax.sum() / len(argmax)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6858b5db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DDPM Sampling loop time step: 100%|██████████| 1000/1000 [00:41<00:00, 24.26it/s]\n"
     ]
    }
   ],
   "source": [
    "def log_prob_fn_extinct(z):\n",
    "    batch_size, latent_dim = z.shape\n",
    "    logits = classifier(z)\n",
    "    log_prob_sum = F.log_softmax(input=logits, dim=1).sum(dim=0)\n",
    "    log_prob_sum[0] *= -1\n",
    "    log_prob = log_prob_sum.sum(dim=0)\n",
    "    return log_prob\n",
    "\n",
    "cond_fn_extinct = gd.get_cond_fn(\n",
    "    log_prob_fn=log_prob_fn_extinct, \n",
    "    guidance_strength=1.0, \n",
    "    clip_grad=True, \n",
    "    clip_grad_max=1.0,\n",
    "    latent_dim=256\n",
    ")\n",
    "\n",
    "z_guided = diffusion.sample(batch_size=16, cond_fn=cond_fn_extinct)\n",
    "z_guided = z_guided.reshape(-1, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20577b63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diffusion Probs: tensor([[2.8466e-02, 9.7153e-01],\n",
      "        [1.8587e-10, 1.0000e+00],\n",
      "        [1.3243e-01, 8.6757e-01],\n",
      "        [2.5237e-08, 1.0000e+00],\n",
      "        [6.3647e-07, 1.0000e+00],\n",
      "        [1.7829e-25, 1.0000e+00],\n",
      "        [2.4681e-05, 9.9998e-01],\n",
      "        [6.6248e-01, 3.3752e-01],\n",
      "        [1.5947e-02, 9.8405e-01],\n",
      "        [3.0473e-03, 9.9695e-01],\n",
      "        [2.7940e-02, 9.7206e-01],\n",
      "        [2.2397e-02, 9.7760e-01],\n",
      "        [3.2246e-01, 6.7754e-01],\n",
      "        [4.7122e-07, 1.0000e+00],\n",
      "        [6.3131e-05, 9.9994e-01],\n",
      "        [8.7907e-03, 9.9121e-01]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "Percent Extinct: 0.9375\n"
     ]
    }
   ],
   "source": [
    "eval_probs(z_guided)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8bd25f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "unet = diffusion.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "63acece8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gdiffusion.diffusion.beta_scheduler import BetaScheduleSigmoid\n",
    "from gdiffusion.diffusion.util import *\n",
    "from functools import partial\n",
    "from collections import namedtuple\n",
    "ModelPrediction =  namedtuple('ModelPrediction', ['pred_noise', 'pred_x_start'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "28d9f4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiffusionSampler(nn.Module):\n",
    "    def __init__(self, model, latent_dim, num_timesteps=1000, device=None):\n",
    "        super().__init__()\n",
    "\n",
    "        self.model = model\n",
    "        self.dim = latent_dim\n",
    "        self.num_timesteps = num_timesteps\n",
    "        self.device = self._get_device(device)\n",
    "        \n",
    "        betas = BetaScheduleSigmoid.get_betas(num_timesteps=num_timesteps)\n",
    "\n",
    "        alphas = 1. - betas\n",
    "        alphas_cumprod = torch.cumprod(alphas, dim=0)\n",
    "        alphas_cumprod_prev = F.pad(alphas_cumprod[:-1], (1, 0), value = 1.)\n",
    "\n",
    "        register_buffer = lambda name, val: self.register_buffer(name, val.to(torch.float32))\n",
    "\n",
    "        register_buffer('betas', betas)\n",
    "        register_buffer('alphas_cumprod', alphas_cumprod)\n",
    "        register_buffer('alphas_cumprod_prev', alphas_cumprod_prev)\n",
    "\n",
    "        # calculations for diffusion q(x_t | x_{t-1}) and others\n",
    "        register_buffer('sqrt_alphas_cumprod', torch.sqrt(alphas_cumprod))\n",
    "        register_buffer('sqrt_one_minus_alphas_cumprod', torch.sqrt(1. - alphas_cumprod))\n",
    "        register_buffer('log_one_minus_alphas_cumprod', torch.log(1. - alphas_cumprod))\n",
    "        register_buffer('sqrt_recip_alphas_cumprod', torch.sqrt(1. / alphas_cumprod))\n",
    "        register_buffer('sqrt_recipm1_alphas_cumprod', torch.sqrt(1. / alphas_cumprod - 1))\n",
    "\n",
    "        # calculations for posterior q(x_{t-1} | x_t, x_0)\n",
    "        posterior_variance = betas * (1. - alphas_cumprod_prev) / (1. - alphas_cumprod)\n",
    "\n",
    "        # above: equal to 1. / (1. / (1. - alpha_cumprod_tm1) + alpha_t / beta_t)\n",
    "        register_buffer('posterior_variance', posterior_variance)\n",
    "\n",
    "        # below: log calculation clipped because the posterior variance is 0 at the beginning of the diffusion chain\n",
    "        register_buffer('posterior_log_variance_clipped', torch.log(posterior_variance.clamp(min =1e-20)))\n",
    "        register_buffer('posterior_mean_coef1', betas * torch.sqrt(alphas_cumprod_prev) / (1. - alphas_cumprod))\n",
    "        register_buffer('posterior_mean_coef2', (1. - alphas_cumprod_prev) * torch.sqrt(alphas) / (1. - alphas_cumprod))\n",
    "\n",
    "        # loss weight\n",
    "        snr = alphas_cumprod / (1 - alphas_cumprod)\n",
    "        loss_weight = snr / (snr + 1)\n",
    "        register_buffer('loss_weight', loss_weight)\n",
    "\n",
    "    def _get_device(self, device=None):\n",
    "        if device is not None:\n",
    "            return device\n",
    "        \n",
    "        device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "        if device != 'cuda':\n",
    "            print(\"Warning: device is {device}, not cuda\")\n",
    "\n",
    "        return device\n",
    "    \n",
    "    def predict_start_from_noise(self, x_t, t, noise):\n",
    "        return (\n",
    "            extract(self.sqrt_recip_alphas_cumprod, t, x_t.shape) * x_t -\n",
    "            extract(self.sqrt_recipm1_alphas_cumprod, t, x_t.shape) * noise\n",
    "        )\n",
    "\n",
    "    def predict_start_from_noise(self, x_t, t, noise):\n",
    "        return (\n",
    "            extract(self.sqrt_recip_alphas_cumprod, t, x_t.shape) * x_t -\n",
    "            extract(self.sqrt_recipm1_alphas_cumprod, t, x_t.shape) * noise\n",
    "        )\n",
    "\n",
    "    def predict_noise_from_start(self, x_t, t, x0):\n",
    "        return (\n",
    "            (extract(self.sqrt_recip_alphas_cumprod, t, x_t.shape) * x_t - x0) / \\\n",
    "            extract(self.sqrt_recipm1_alphas_cumprod, t, x_t.shape)\n",
    "        )\n",
    "\n",
    "    def predict_v(self, x_start, t, noise):\n",
    "        return (\n",
    "            extract(self.sqrt_alphas_cumprod, t, x_start.shape) * noise -\n",
    "            extract(self.sqrt_one_minus_alphas_cumprod, t, x_start.shape) * x_start\n",
    "        )\n",
    "\n",
    "    def predict_start_from_v(self, x_t, t, v):\n",
    "        return (\n",
    "            extract(self.sqrt_alphas_cumprod, t, x_t.shape) * x_t -\n",
    "            extract(self.sqrt_one_minus_alphas_cumprod, t, x_t.shape) * v\n",
    "        )\n",
    "\n",
    "    def q_posterior(self, x_start, x_t, t):\n",
    "        posterior_mean = (\n",
    "            extract(self.posterior_mean_coef1, t, x_t.shape) * x_start +\n",
    "            extract(self.posterior_mean_coef2, t, x_t.shape) * x_t\n",
    "        )\n",
    "        posterior_variance = extract(self.posterior_variance, t, x_t.shape)\n",
    "        posterior_log_variance_clipped = extract(self.posterior_log_variance_clipped, t, x_t.shape)\n",
    "        return posterior_mean, posterior_variance, posterior_log_variance_clipped\n",
    "    \n",
    "    def model_predictions(self, x, t):\n",
    "        v = self.model(x, t)\n",
    "\n",
    "        x_start = self.predict_start_from_v(x, t, v)\n",
    "        pred_noise = self.predict_noise_from_start(x, t, x_start)\n",
    "\n",
    "        return ModelPrediction(pred_noise, x_start)\n",
    "    \n",
    "    def mean_variance(self,x, t):\n",
    "        preds = self.model_predictions(x, t)\n",
    "        x_start = preds.pred_x_start\n",
    "        pred_noise = preds.pred_noise\n",
    "\n",
    "        model_mean, posterior_variance, posterior_log_variance = self.q_posterior(x_start = x_start, x_t = x, t = t)\n",
    "        return model_mean, posterior_variance, posterior_log_variance, x_start\n",
    "\n",
    "    def sample(self, batch_size=16, return_all_timesteps=False, cond_fn=None, *args):\n",
    "        raise NotImplementedError(\"Sample must be derived\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "536b47ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DDIMSampler(DiffusionSampler):\n",
    "    def __init__(self, model, latent_dim, num_timesteps=1000, sampling_timesteps=None, device=None, ddim_sampling_eta=0.,):\n",
    "        super().__init__(model, latent_dim, num_timesteps, device)\n",
    "        self.sampling_timesteps = sampling_timesteps\n",
    "        self.ddim_sampling_eta = ddim_sampling_eta\n",
    "\n",
    "    def condition_score(self, cond_fn, pred_noise, x_start, x, t):\n",
    "        alpha_bar = extract(self.alphas_cumprod, t, x.shape)\n",
    "        new_pred_noise = pred_noise - (1 - alpha_bar).sqrt() * cond_fn(x, t)\n",
    "        \n",
    "        new_x_start = self.predict_start_from_noise(x, t, new_pred_noise)\n",
    "\n",
    "        return new_x_start, pred_noise\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def sample(self, batch_size=16, return_all_timesteps=False, cond_fn=None):\n",
    "        shape = (batch_size, 1, self.dim)\n",
    "        eta = self.ddim_sampling_eta\n",
    "\n",
    "        times = torch.linspace(-1, self.num_timesteps - 1, steps=self.sampling_timesteps + 1)\n",
    "        times = list(reversed(times.int().tolist()))\n",
    "        time_pairs = list(zip(times[:-1], times[1:])) # [(T-1, T-2), (T-2, T-3), ..., (1, 0), (0, -1)]\n",
    "\n",
    "        x = torch.randn(shape, device=self.device)\n",
    "\n",
    "        for time, time_next in tqdm(time_pairs, desc = 'DDIM Sampling Loop Time Step'):\n",
    "            time_cond = torch.full((batch_size,), time, device=self.device, dtype=torch.long)\n",
    "            pred_noise, x_start = self.model_predictions(x, time_cond)\n",
    "\n",
    "            if cond_fn is not None:\n",
    "                new_x_start, new_pred_noise = self.condition_score(cond_fn, pred_noise, x_start, x, time_cond)\n",
    "                x_start = new_x_start\n",
    "                pred_noise = new_pred_noise\n",
    "\n",
    "            if time_next < 0:\n",
    "                x = x_start\n",
    "                continue\n",
    "\n",
    "            alpha = self.alphas_cumprod[time]\n",
    "            alpha_next = self.alphas_cumprod[time_next]\n",
    "\n",
    "            sigma = eta * ((1 - alpha / alpha_next) * (1 - alpha_next) / (1 - alpha)).sqrt()\n",
    "            c = (1 - alpha_next - sigma ** 2).sqrt()\n",
    "\n",
    "            noise = torch.randn_like(x)\n",
    "\n",
    "            x = x_start * alpha_next.sqrt() + \\\n",
    "                  c * pred_noise + \\\n",
    "                  sigma * noise\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e4f897",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "3d66ea76",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DDIM Sampling Loop Time Step: 100%|██████████| 500/500 [00:20<00:00, 24.14it/s]\n"
     ]
    }
   ],
   "source": [
    "ddim = DDIMSampler(model=unet.to('cuda'), latent_dim=256, num_timesteps=1000, sampling_timesteps=500, device='cuda').to(device)\n",
    "cond_fn_extinct_10 = gd.get_cond_fn(\n",
    "    log_prob_fn=log_prob_fn_extinct, \n",
    "    guidance_strength=2.0, \n",
    "    clip_grad=True, \n",
    "    clip_grad_max=1.0,\n",
    "    latent_dim=256\n",
    ")\n",
    "z_ddim = ddim.sample(batch_size=16, cond_fn=cond_fn_extinct_10).reshape(-1, 256)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "28460618",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 57.8160, -52.5945,  61.0330,  ..., -47.9392, -81.4191, -80.5274],\n",
       "        [ 69.0803, -67.9495,  63.3505,  ..., -67.3417, -73.5253, -77.0669],\n",
       "        [ 68.8275, -58.3579,  60.3463,  ..., -62.5844, -78.9527, -71.2014],\n",
       "        ...,\n",
       "        [ 74.1794, -69.7479,  60.5194,  ..., -61.6581, -79.1902, -76.8611],\n",
       "        [ 64.5007, -68.8190,  55.3076,  ..., -54.2688, -78.8820, -82.4434],\n",
       "        [ 79.0259, -63.6021,  61.4692,  ..., -65.1815, -75.6009, -80.9547]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_ddim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "1f457d8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diffusion Probs: tensor([[1.2451e-07, 1.0000e+00],\n",
      "        [1.0000e+00, 9.0503e-11],\n",
      "        [9.8874e-01, 1.1256e-02],\n",
      "        [1.0000e+00, 6.7999e-08],\n",
      "        [1.6868e-05, 9.9998e-01],\n",
      "        [1.0000e+00, 1.9122e-06],\n",
      "        [9.9998e-01, 1.9980e-05],\n",
      "        [1.0000e+00, 5.3889e-08],\n",
      "        [1.0000e+00, 5.8288e-09],\n",
      "        [9.9960e-01, 3.9647e-04],\n",
      "        [9.7899e-01, 2.1005e-02],\n",
      "        [1.0000e+00, 1.1943e-10],\n",
      "        [1.0000e+00, 5.0092e-09],\n",
      "        [9.9999e-01, 1.3650e-05],\n",
      "        [9.9999e-01, 5.2688e-06],\n",
      "        [1.0000e+00, 1.2181e-10]], device='cuda:0', grad_fn=<SoftmaxBackward0>)\n",
      "Percent Extinct: 0.125\n"
     ]
    }
   ],
   "source": [
    "eval_probs(z_ddim)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-cuda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
