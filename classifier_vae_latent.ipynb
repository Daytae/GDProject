{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from tqdm import tqdm\n",
    "import h5py\n",
    "\n",
    "from util.util import get_device\n",
    "device = get_device()\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "PEPTIDE_DATASET_PATH = \"data/peptide_dataset.h5\"\n",
    "PEPTIDE_DATASET_LEN = 14774723 # speed up loading\n",
    "EXTINCT_CLASSIFIER_BEST_PATH = \"saved_models/final_extinct_model_1.pt\"\n",
    "\n",
    "from gdiffusion.classifier.extinct_predictor import EsmClassificationHead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PeptideLatentDataset(Dataset):\n",
    "    def __init__(self, file_loc, latent_dim=256, latent_name='LATENTS', extinct_name='EXTINCT', dataset_len=None, transform=None):\n",
    "        # keep file open\n",
    "        self.file = h5py.File(file_loc, 'r')\n",
    "        self.latent_dataset = self.file[latent_name]\n",
    "        self.extinct_dataset = self.file[extinct_name]\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "        self._cached_len = dataset_len if dataset_len is not None else len(self.latent_dataset[:])\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self, use_cached=True):\n",
    "        if use_cached:\n",
    "            return self._cached_len\n",
    "        else:\n",
    "            return len(self.latent_dataset[:])\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        raw_latent = self.latent_dataset[idx]\n",
    "        raw_extinct = np.array(self.extinct_dataset[idx], dtype=np.int32)\n",
    "\n",
    "        latent = torch.FloatTensor(data=raw_latent)\n",
    "        labels = torch.LongTensor(data=raw_extinct)\n",
    "\n",
    "        out = (latent,  labels)\n",
    "        if self.transform:\n",
    "            out = self.transform(out)\n",
    "        return out\n",
    "    \n",
    "class EsmClassificationHead(nn.Module):\n",
    "    # slightly modified from the original ESM classification head\n",
    "    def __init__(self, input_dim=256):\n",
    "        super().__init__()\n",
    "        self.dense = nn.Linear(input_dim, 2048)\n",
    "        self.dropout = nn.Dropout(0.05)\n",
    "        self.dense2 = nn.Linear(2048, 2048)\n",
    "        self.dense3 = nn.Linear(2048, 2048)\n",
    "        self.out_proj = nn.Linear(2048, 2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.dropout(x)\n",
    "        x = self.dense(x)\n",
    "        x = F.silu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.dense2(x)\n",
    "        x = F.silu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.dense3(x)\n",
    "        x = F.silu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.out_proj(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3859/494377095.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  classifier.load_state_dict(torch.load(EXTINCT_CLASSIFIER_BEST_PATH)['model_state_dict'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = EsmClassificationHead()\n",
    "classifier.load_state_dict(torch.load(EXTINCT_CLASSIFIER_BEST_PATH)['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training data...\n"
     ]
    }
   ],
   "source": [
    "def train_epoch(model, train_loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for embeddings, labels in tqdm(train_loader, desc=\"Training\"):\n",
    "        embeddings, labels = embeddings.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        logits = model(embeddings)\n",
    "\n",
    "        loss = criterion(logits, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    return total_loss / len(train_loader)\n",
    "\n",
    "def evaluate(model, data_loader, device):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    true_labels = []\n",
    "    \n",
    "    with torch.inference_mode():\n",
    "        for embeddings, labels in tqdm(data_loader, desc=\"Evaluating\"):\n",
    "            embeddings = embeddings.to(device)\n",
    "            logits = model(embeddings)\n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "            predictions.extend(preds.cpu().numpy())\n",
    "            true_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    predictions = np.array(predictions)\n",
    "    true_labels = np.array(true_labels)\n",
    "    \n",
    "    return {\n",
    "        'accuracy': accuracy_score(true_labels, predictions),\n",
    "        'precision': precision_score(true_labels, predictions),\n",
    "        'recall': recall_score(true_labels, predictions),\n",
    "        'f1': f1_score(true_labels, predictions)\n",
    "    }\n",
    "\n",
    "print(\"Loading training data...\")\n",
    "peptide_latent_dataset = PeptideLatentDataset(PEPTIDE_DATASET_PATH, latent_dim=256, dataset_len=PEPTIDE_DATASET_LEN)\n",
    "\n",
    "\n",
    "# 90/10 split\n",
    "train_size = int(0.9 * len(peptide_latent_dataset))\n",
    "test_size = len(peptide_latent_dataset) - train_size\n",
    "\n",
    "train_dataset, test_dataset = random_split(peptide_latent_dataset, [train_size, test_size])\n",
    "\n",
    "\n",
    "# Create dataloaders\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=1024,\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    "    pin_memory=True\n",
    ")\n",
    "    \n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=1024,\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    "    pin_memory=True\n",
    ")\n",
    "    \n",
    "model = EsmClassificationHead().to(device)\n",
    "criterion = nn.CrossEntropyLoss()  # Changed to CrossEntropyLoss for 2-class output\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['model_state_dict', 'optimizer_state_dict', 'final_metrics', 'best_accuracy', 'input_dim'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3859/2985312342.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  sd = torch.load(f=\"saved_models/final_extinct_model_1.pt\")\n"
     ]
    }
   ],
   "source": [
    "sd = torch.load(f=\"saved_models/final_extinct_model_1.pt\")\n",
    "print(sd.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(sd['model_state_dict'])\n",
    "optimizer.load_state_dict(sd['optimizer_state_dict'])\n",
    "metrics = sd['final_metrics']\n",
    "best_accuracy = sd['best_accuracy']\n",
    "input_dim = sd['input_dim']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1.7174, -1.6824], device='cuda:0')\n",
      "tensor([ 11805.5635, -11533.3574], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Weird puzzle, gradient blows up on random but not train?\n",
    "classifier.eval()\n",
    "classifier.to('cuda')\n",
    "with torch.no_grad():\n",
    "    z, _ = train_dataset[200]\n",
    "    z = z.to('cuda')\n",
    "    print(classifier(z))\n",
    "\n",
    "    print(classifier(torch.randn_like(z, device=z.device, dtype=z.dtype)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-3.4326, device='cuda:0', grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   2%|▏         | 32/1443 [00:07<05:34,  4.21it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m metrics \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[11], line 24\u001b[0m, in \u001b[0;36mevaluate\u001b[0;34m(model, data_loader, device)\u001b[0m\n\u001b[1;32m     21\u001b[0m true_labels \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39minference_mode():\n\u001b[0;32m---> 24\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m embeddings, labels \u001b[38;5;129;01min\u001b[39;00m tqdm(data_loader, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEvaluating\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     25\u001b[0m         embeddings \u001b[38;5;241m=\u001b[39m embeddings\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     26\u001b[0m         logits \u001b[38;5;241m=\u001b[39m model(embeddings)\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch-cuda/lib/python3.10/site-packages/tqdm/std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1181\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1182\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1183\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1184\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch-cuda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:701\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    699\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 701\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[1;32m    707\u001b[0m ):\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch-cuda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:757\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    755\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    756\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 757\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    758\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    759\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch-cuda/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:50\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__getitems__\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__:\n\u001b[0;32m---> 50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__getitems__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch-cuda/lib/python3.10/site-packages/torch/utils/data/dataset.py:420\u001b[0m, in \u001b[0;36mSubset.__getitems__\u001b[0;34m(self, indices)\u001b[0m\n\u001b[1;32m    418\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    419\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 420\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx]] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices]\n",
      "File \u001b[0;32m~/miniconda3/envs/pytorch-cuda/lib/python3.10/site-packages/torch/utils/data/dataset.py:420\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    418\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    419\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 420\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices]\n",
      "Cell \u001b[0;32mIn[9], line 23\u001b[0m, in \u001b[0;36mPeptideLatentDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     20\u001b[0m raw_extinct \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mextinct_dataset[idx], dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mint32)\n\u001b[1;32m     22\u001b[0m latent \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mFloatTensor(data\u001b[38;5;241m=\u001b[39mraw_latent)\n\u001b[0;32m---> 23\u001b[0m labels \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLongTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mraw_extinct\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m out \u001b[38;5;241m=\u001b[39m (latent,  labels)\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "metrics = evaluate(model, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 12986/12986 [14:26<00:00, 14.99it/s]\n",
      "Evaluating: 100%|██████████| 1443/1443 [01:13<00:00, 19.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/5\n",
      "Train Loss: 0.4554\n",
      "Test Metrics:\n",
      "accuracy: 0.8056\n",
      "precision: 0.6932\n",
      "recall: 0.5790\n",
      "f1: 0.6310\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 12986/12986 [13:30<00:00, 16.02it/s]\n",
      "Evaluating: 100%|██████████| 1443/1443 [01:14<00:00, 19.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2/5\n",
      "Train Loss: 0.4127\n",
      "Test Metrics:\n",
      "accuracy: 0.8147\n",
      "precision: 0.6970\n",
      "recall: 0.6273\n",
      "f1: 0.6603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 12986/12986 [13:25<00:00, 16.13it/s]\n",
      "Evaluating: 100%|██████████| 1443/1443 [01:12<00:00, 19.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3/5\n",
      "Train Loss: 0.3919\n",
      "Test Metrics:\n",
      "accuracy: 0.8274\n",
      "precision: 0.7289\n",
      "recall: 0.6347\n",
      "f1: 0.6786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 12986/12986 [13:16<00:00, 16.30it/s]\n",
      "Evaluating: 100%|██████████| 1443/1443 [01:17<00:00, 18.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4/5\n",
      "Train Loss: 0.3770\n",
      "Test Metrics:\n",
      "accuracy: 0.8326\n",
      "precision: 0.7305\n",
      "recall: 0.6608\n",
      "f1: 0.6939\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 12986/12986 [13:32<00:00, 15.98it/s]\n",
      "Evaluating: 100%|██████████| 1443/1443 [01:18<00:00, 18.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 5/5\n",
      "Train Loss: 0.3620\n",
      "Test Metrics:\n",
      "accuracy: 0.8417\n",
      "precision: 0.7650\n",
      "recall: 0.6475\n",
      "f1: 0.7014\n",
      "\n",
      "Training completed!\n",
      "Best test accuracy: 0.8417\n"
     ]
    }
   ],
   "source": [
    "# # Training loop\n",
    "# num_epochs = 5\n",
    "# best_accuracy = 0\n",
    "    \n",
    "# print(\"Starting training...\")\n",
    "# for epoch in range(num_epochs):\n",
    "#     train_loss = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "#     metrics = evaluate(model, test_loader, device)\n",
    "    \n",
    "#     print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "#     print(f\"Train Loss: {train_loss:.4f}\")\n",
    "#     print(f\"Test Metrics:\")\n",
    "#     for metric, value in metrics.items():\n",
    "#         print(f\"{metric}: {value:.4f}\")\n",
    "    \n",
    "#     # Save best model\n",
    "#     if metrics['accuracy'] > best_accuracy:\n",
    "#         best_accuracy = metrics['accuracy']\n",
    "#         torch.save(model.state_dict(), 'train/best_extinct_model.pt')\n",
    "\n",
    "# # Save final model and training info\n",
    "# final_save = {\n",
    "#     'model_state_dict': model.state_dict(),\n",
    "#     'optimizer_state_dict': optimizer.state_dict(),\n",
    "#     'final_metrics': metrics,\n",
    "#     'best_accuracy': best_accuracy,\n",
    "#     'input_dim': 256\n",
    "# }\n",
    "# torch.save(final_save, 'train/final_extinct_model.pt')\n",
    "\n",
    "# print(\"\\nTraining completed!\")\n",
    "# print(f\"Best test accuracy: {best_accuracy:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-cuda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
